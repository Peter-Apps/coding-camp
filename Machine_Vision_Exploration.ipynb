{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YSXL2SzBT3DY",
        "zalGqItQDEzr"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Peter-Apps/coding-camp/blob/main/Machine_Vision_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Vision using Colab\n",
        "\n"
      ],
      "metadata": {
        "id": "fq44MnF1BhEh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI Image recognition is a rapidly advancing field that has applications in a wide variety of topics. From readling license plates for automatic tolling, to organizing your photos, this technology is becoming an integral part of our lives.\n",
        "\n",
        "In this notebook we're going to use a pre-built model to try to recognize images we create. The goal here isn't to fully understand how the model \"knows\" what is in the image, but rather to see some of the limitations in the model and it's implications for us.\n",
        "\n",
        "For this activity we're using a model trained by [Keras](https://keras.io/about/). Keras is free to use and has several models for a variety of machine learning tasks including Vision and Natural Language (think ChatGPT) workflows."
      ],
      "metadata": {
        "id": "8s8ulLRQBoMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the Model"
      ],
      "metadata": {
        "id": "VXmlV3VaCydB"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaaJRNmXRzuq"
      },
      "source": [
        "First, import some libraries that you'll need:\n",
        "\n",
        "*   `tensorflow` does the actual machine learning and image recognition work\n",
        "*   `os` accesses the operating system, to work with the stored image file\n",
        "*   `maplotlib.pyplot` displays the image in the Colab notebook\n",
        "*   `numpy` is used to help convert the image into numbers for the model to read\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG2vpA8FLCww"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baItUUKnTBI1"
      },
      "source": [
        "Load the model that will identify your images. In this case we're using the VGG16 model. You can find a list of all the pre-trained models in the Keras application as well as their performance [here](https://keras.io/api/applications/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duEfdVqldNSF"
      },
      "source": [
        "model = tf.keras.applications.VGG16()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating helper functions"
      ],
      "metadata": {
        "id": "oY00laJzC57H"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRMFnAhURbi5"
      },
      "source": [
        "The `get_image_from_url` function below takes a URL, fetches the image at it, and stores it in a file.\n",
        "It then returns the path to the file. This lets you take an image from the internet and turn it into a local file you can give to your model.\n",
        "\n",
        "It will fail if the image at the URL cannot be read by a machine. Wikipedia images are a good way to avoid this, as is uploading images to your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTi1TFg-S3AE"
      },
      "source": [
        "def get_image_from_url(image_url):\n",
        "  # If the temporary test_image.jpg file already exists,\n",
        "  # delete it so a new one can be made.\n",
        "  if os.path.exists('/root/.keras/datasets/test_image.jpg'):\n",
        "    os.remove('/root/.keras/datasets/test_image.jpg')\n",
        "\n",
        "  image_path = tf.keras.utils.get_file('test_image.jpg', origin=image_url)\n",
        "  return image_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `load_image` function takes a path to an image (either a local path or an image path from `get_image_from_url` and loads it into memory. This image gets printed on the screen and then passed to the `classify_image` function."
      ],
      "metadata": {
        "id": "oAXyF0ftFuab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(image_path):\n",
        "  image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  return image"
      ],
      "metadata": {
        "id": "F17D5IM0W3eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jH2g6hC3RX1z"
      },
      "source": [
        "The `print_classifications` function takes a list of predictions, looks up the labels for them,\n",
        "then prints the labels and the weight the model has given to that label. It will save you some work later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA_1c5f407cg"
      },
      "source": [
        "def print_classifications(classifications):\n",
        "    for (classification, number) in zip(classifications[0], range(1, len(classifications[0])+1)):\n",
        "      print('{}. {} {:.2f}%'.format(number, classification[1], classification[2]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Putting it all together, we have the `classify_image` function which runs the model on an image and prints out the classifications."
      ],
      "metadata": {
        "id": "wTp5lWR034MV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD2D_ogHeGMS"
      },
      "source": [
        "def classify_image(image):\n",
        "  image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "  image = np.expand_dims(image, axis=0)\n",
        "  classification_result = model.predict(image, batch_size=1)\n",
        "  classifications = tf.keras.applications.imagenet_utils.decode_predictions(classification_result, top=15)\n",
        "  print_classifications(classifications)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSXL2SzBT3DY"
      },
      "source": [
        "## Try it with an online image:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = get_image_from_url('https://dojo.soy/predict-dog')\n",
        "image = load_image(image_path)\n",
        "classify_image(image)"
      ],
      "metadata": {
        "id": "Bah3rF3rEAn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice! We now have the predictions from the image as well as the % confidence the model has in the result.\n",
        "\n",
        "Questions to discuss:\n",
        "1. Do you notice anything strange about these predictions?\n",
        "2. Why do you think that could be?"
      ],
      "metadata": {
        "id": "u55bAFjyaERP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify your own image"
      ],
      "metadata": {
        "id": "wZWbbtFbatNd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To try this with your own images, find a link to an image file and replace the `image_url` parameter below with the link (remember to keep it in quotes).\n",
        "\n",
        "[Wikipedia's Featured Images](https://en.wikipedia.org/wiki/Wikipedia:Featured_pictures) is a great place to find items to test. Simply right click on an image and choose Copy Image Address to get the link."
      ],
      "metadata": {
        "id": "xutBve0DaxZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/9/95/Olympus_E-M1_Mark_III_Zuiko_12-100mm.jpg/1920px-Olympus_E-M1_Mark_III_Zuiko_12-100mm.jpg\"\n",
        "image_path = get_image_from_url(image_url)\n",
        "image = load_image(image_path)\n",
        "classify_image(image)\n"
      ],
      "metadata": {
        "id": "MCeeUL2ka80K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions to discuss:\n",
        "1. How did the model work?\n",
        "2. Were it's predictions close to the actual image? If yes, can you find an image that breaks it's predictions?\n",
        "3. If not, why do you think that was?"
      ],
      "metadata": {
        "id": "ZYUfx9iTbzDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model with your webcam"
      ],
      "metadata": {
        "id": "zalGqItQDEzr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code block below creates a window to capture an image from the webcam. These images are only stored in this runtime and will be automatically deleted when this session ends."
      ],
      "metadata": {
        "id": "Y2WxyA2SDKSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "VIDEO_HTML = \"\"\"\n",
        "<div class=\"video_container\">\n",
        "  <video autoplay\n",
        "   width=%d height=%d></video>\n",
        "  <div style='position: absolute;top: 40px; left: 40px; font-size: 40px; color: green;'>Click to save!</div>\n",
        "</div>\n",
        "<script>\n",
        "var video = document.querySelector('video')\n",
        "navigator.mediaDevices.getUserMedia({ video: true })\n",
        "  .then(stream=> video.srcObject = stream)\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "  video.onclick = ()=>{\n",
        "    var canvas = document.createElement('canvas')\n",
        "    var [w,h] = [video.offsetWidth, video.offsetHeight]\n",
        "    canvas.width = w\n",
        "    canvas.height = h\n",
        "    canvas.getContext('2d')\n",
        "          .drawImage(video, 0, 0, w, h)\n",
        "    video.srcObject.getVideoTracks()[0].stop()\n",
        "    video.replaceWith(canvas)\n",
        "    resolve(canvas.toDataURL('image/jpeg', %f))\n",
        "  }\n",
        "})\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def take_photo(filename=None, quality=0.8, size=(800,600)):\n",
        "  handle = display(HTML(VIDEO_HTML % (size[0],size[1],quality)), display_id='videoHTML')\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  if filename:\n",
        "    f = io.BytesIO(binary)\n",
        "    Image.open(f).save(filename)\n",
        "  else:\n",
        "    f = io.BytesIO(binary)\n",
        "    return np.asarray(Image.open(f))\n",
        "\n",
        "def classifyWebcamPhoto():\n",
        "  take_photo(\"Test.jpeg\")\n",
        "  path = \"/content/Test.jpeg\"\n",
        "  image = load_image(path)\n",
        "  classify_image(image)"
      ],
      "metadata": {
        "id": "qERJjEJkWIYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the code block below to take a photo. For best results, try to keep the background clear and hold the object as close to the camera as possible."
      ],
      "metadata": {
        "id": "F_LrmkrfDgj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifyWebcamPhoto()"
      ],
      "metadata": {
        "id": "y_PpxP5hWMzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions to discuss:\n",
        "1. How well did the model predict the image?\n",
        "2. Was it better, worse, or about the same as the online images?\n",
        "\n",
        "Based on your results answer the following questions:\n",
        "3. What types of images do you think this model was trained on?\n",
        "4. In what use cases would you feel comfortable using this model to identify objects?\n",
        "5. Are there any areas where you wouldn't trust this model's predictions? Why or why not?\n"
      ],
      "metadata": {
        "id": "9MRTIV9IcK66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Credits:\n",
        "This notebook builds upon the example [Testing your computer's vision](https://projects.raspberrypi.org/en/projects/testing-your-computers-vision/0) activity published by the Raspberry Pi Foundation.\n",
        "\n",
        "That activity and this notebook are released under a [CC BY-SA 4.0 DEED License](https://creativecommons.org/licenses/by-sa/4.0/)"
      ],
      "metadata": {
        "id": "tQ39CN6VYGaT"
      }
    }
  ]
}